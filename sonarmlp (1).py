# -*- coding: utf-8 -*-
"""sonarmlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1swVowkeS25PQse--Gx2kjT8EM28i3nLx
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, roc_curve, auc
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score

df = pd.read_csv('sonar.csv')

df.head()

df.tail()

df.isnull().sum()

feature_names = ['feat' + str(i) for i in range(1, 61)]
df.columns = feature_names + ['label']

df.info()

df['label'] = df['label'].map({'R': 0, 'M': 1})

X = df[feature_names].values
y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, stratify=y, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

param_grid = {
    'hidden_layer_sizes': [(6,), (12,), (24,), (12, 6)],
    'learning_rate_init': [0.001, 0.01, 0.1],
    'alpha': [0.0001, 0.001, 0.01],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd']
}

mlp = MLPClassifier(max_iter=300, random_state=42)

"""grid seach cv



             
             
            n_jobs=-1,
             param_grid={'activation': ['relu', 'tanh'],
                         'alpha': [0.0001, 0.001, 0.01],
                         'hidden_layer_sizes': [(6,), (12,), (24,), (12, 6)],
                         'learning_rate_init': [0.001, 0.01, 0.1],
                         'solver': ['adam', 'sgd']},
             scoring='accuracy'
"""

grid = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid.fit(X_train_scaled, y_train)

print("Bests:", grid.best_params_)
print("Best validation acc: {:.2f}%".format(grid.best_score_ * 100))

best_model = grid.best_estimator_
y_pred = best_model.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_pred)
print("Test Set Accuracy: {:.2f}%".format(test_accuracy * 100))

y_proba = best_model.predict_proba(X_test_scaled)[:, 1]

fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)
print("AUC Score: {:.2f}".format(roc_auc))

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("F1-Score: {:.2f}".format(f1))

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

if hasattr(best_model, "loss_curve_"):
    plt.figure(figsize=(8, 6))
    plt.plot(best_model.loss_curve_, marker='o')
    plt.title('Training Loss Curve')
    plt.xlabel('Iteration')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.show()

!pip install nbconvert

!jupyter nbconvert --to html  /content/sonarmlp.ipynb